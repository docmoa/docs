---
description: 랭체인, RAG, 에이전트로 신뢰성 있는 LLM 활용
tag: ["book", "llm", "ai", "prompt-engineering"]
---

# Chapter 1. 프롬프트 엔지니어링 개요

::: tip
프롬프트 엔지니어링은 LLM의 능력을 최대한 끌어내고 할루시네이션을 막기 위한 핵심 기술이다. 프롬프트를 잘 설계하면 LLM의 창조적 특성을 살리면서도 신뢰할 수 있는 결과를 얻을 수 있다.
:::

## 1.1 프롬프트 엔지니어링이란

### 정의

프롬프트 엔지니어링(Prompt Engineering)이란, 간단히 말해 LLM과 제대로 소통하기 위한 기술이다. 대규모 언어 모델(Large Language Model, LLM)과 효과적으로 대화하려면 프롬프트를 잘 설계해야 한다. 프롬프트는 모델에게 보내는 입력 텍스트인데, 이게 제대로 작성되면 원하는 답을 얻을 수 있다. 반대로 엉성하게 작성하면 엉뚱한 답이 나오기도 한다.

### 왜 해야 하는가?

LLM은 강력한 능력을 가지고 있지만, 프롬프트의 품질에 따라 결과가 크게 달라진다. 같은 모델이라도 프롬프트를 어떻게 작성하느냐에 따라:

- **정확도**: 올바른 답변을 생성할 확률이 크게 달라진다
- **일관성**: 동일한 입력에 대해 일관된 결과를 얻을 수 있다
- **할루시네이션 감소**: 잘못된 정보를 생성하는 빈도를 줄일 수 있다
- **비용 효율성**: 더 적은 토큰으로 원하는 결과를 얻을 수 있다

### 예시

**나쁜 프롬프트 예시:**
```
파리
```
→ 모델이 도시인지 곤충인지, 아니면 다른 의미인지 불명확

**좋은 프롬프트 예시:**
```
프랑스의 수도는 어디인가요? 한 단어로 답변해주세요.
```
→ 명확한 지시와 형식 요구사항으로 정확한 답변 유도

**더 나은 프롬프트 예시:**
```
다음 질문에 대해 정확하고 간결하게 답변해주세요. 
만약 확실하지 않다면 "모르겠습니다"라고 답변하세요.

질문: 프랑스의 수도는 어디인가요?
```
→ 불확실한 경우의 처리 방법까지 명시하여 할루시네이션 방지

## 1.2 대규모 언어 모델 (Large Language Model, LLM)

### 작동 원리

대규모 언어 모델은 수조 개의 파라미터를 가진 신경망이다. 방대한 텍스트 데이터로 학습된다. 

1. **학습 과정**: 인터넷, 책, 논문 등 다양한 텍스트 데이터에서 언어 패턴을 학습
2. **예측 기반**: 다음 토큰(단어 단위)을 예측하는 방식으로 텍스트 생성
3. **확률 분포**: 각 토큰에 대한 확률 분포를 계산하여 가장 가능성 높은 토큰 선택
4. **자기회귀적 생성**: 이전에 생성한 토큰을 기반으로 다음 토큰을 계속 생성

### 주요 종류

- **GPT 시리즈** (OpenAI)
  - GPT-3.5, GPT-4, GPT-4 Turbo: ChatGPT의 기반 모델
  - GPT-4 Turbo: 128K 컨텍스트 윈도우, 2023년 4월까지 학습 데이터
  - 강력한 일반적 능력과 대화 능력
  - 챗봇 및 일반 대화 작업에서 우수한 성능

- `Claude` (Anthropic)
  - Claude 3 Opus, Sonnet, Haiku
  - Claude 3.7 Sonnet: 추론 전용 모델 (Reasoning LLM)
  - Claude Opus 4.5: AI 코딩 작업에서 최고 성능 (SWE-bench Verified 80.9%)
  - 통합 성능에서 최우수 평가
  - 안전성과 정확성에 중점

- `Gemini` (Google)
  - Gemini Pro, Ultra, Nano
  - Gemini 2.5 Pro: 추론 전용 모델 (Reasoning LLM)
  - Gemini 3 Pro: 과학·연구·비즈니스 작업에 특화
  - 멀티모달(텍스트, 이미지, 비디오, 오디오) 처리 능력
  - 32K 시퀀스 길이, 98% 정확도로 컨텍스트 내 값 검색

- **LLaMA** (Meta)
  - LLaMA 3: 8B, 70B, 400B (발표됨)
  - 오픈소스 모델
  - 다양한 크기와 특화 버전 제공
  - LLaMA 3 70B는 Gemini Pro 1.5와 Claude 3 Sonnet을 능가하는 성능

- **Mixtral** (Mistral AI)
  - Mixtral 8x7B, Mixtral 8x22B
  - Mixture of Experts (MoE) 아키텍처
  - 오픈소스 모델 중 우수한 성능

- **중국 모델 (가성비 우수)**
  - **DeepSeek V3.2**: 대용량 처리 및 가성비 최고
  - **Qwen**: 저렴한 대용량 처리에 특화
  - 중국 모델들은 가성비 측면에서 최고 평가

- **추론 전용 모델 (Reasoning LLMs)**
  - Gemini 2.5 Pro, Claude 3.7 Sonnet, o3
  - 명시적으로 추론 능력을 학습한 모델
  - Chain-of-Thought 추론에 특화
  - AI 에이전트 작업에 적합

- **용도별 특화 모델 동향**
  - **AI 코딩**: Claude Opus 4.5가 최고 성능
  - **가성비**: DeepSeek V3.2, Qwen 등 중국 모델
  - **AI 에이전트**: 추론 전용 모델 (Reasoning LLMs)이 적합
  - **챗봇**: GPT 시리즈가 우수
  - **창작**: GPT 시리즈가 우수
  - **과학·연구·비즈니스**: Gemini 3 Pro가 특화
  - 2024-2025년 트렌드: 통합 기능보다 용도별 특화 모델 선호

### 단점

1. **할루시네이션 (Hallucination)**
   - 사실이 아닌 내용을 마치 사실인 것처럼 생성
   - 학습 데이터에 없는 정보를 만들어냄
   - 매우 그럴듯하게 보이지만 실제로는 틀린 답변

2. **지식의 시한성**
   - 학습 시점 이후의 정보를 알지 못함
   - 최신 정보에 대한 접근 불가

3. **컨텍스트 길이 제한**
   - 한 번에 처리할 수 있는 토큰 수에 제한
   - 최신 모델은 긴 컨텍스트 지원 (예: GPT-4 Turbo 128K, Gemini 32K)
   - 하지만 여전히 매우 긴 문서나 대화의 맥락 손실 가능

4. **비용과 지연시간**
   - 대규모 모델 사용 시 높은 API 비용
   - 응답 생성 시간이 길 수 있음

5. **편향성 (Bias)**
   - 학습 데이터의 편향이 모델에 반영
   - 특정 그룹이나 관점에 대한 편향된 답변

### 할루시네이션 (Hallucination)

할루시네이션은 LLM이 학습 데이터에 없거나 사실과 다른 정보를 만들어내는 현상이다. 이건 단순한 버그가 아니다. LLM의 근본적인 특성이다.

**왜 발생하는가?**

1. **확률 기반 생성**: 모델이 가장 가능성 높은 다음 단어를 선택하지만, 항상 정확한 것은 아님
2. **패턴 학습**: 학습 데이터의 패턴을 학습하지만, 사실 여부를 검증하지 않음
3. **컨텍스트 부족**: 질문에 대한 충분한 컨텍스트가 없을 때 추측으로 답변
4. **창조적 특성**: LLM은 본질적으로 창조적이어서 새로운 내용을 만들어냄

**할루시네이션의 종류**

- **사실적 할루시네이션**: 존재하지 않는 사실을 생성
- **인용 할루시네이션**: 존재하지 않는 출처나 인용을 생성
- **논리적 할루시네이션**: 논리적으로 일관되지 않은 답변

**할루시네이션을 줄이는 방법**

- 명확하고 구체적인 프롬프트 작성
- RAG(Retrieval-Augmented Generation)를 통한 사실 기반 답변
- "모르겠습니다" 같은 답변 허용
- 답변 검증 및 사실 확인 단계 추가

## 1.3 오늘날의 프롬프팅 기법들

### 제로샷 프롬프팅 (Zero-shot Prompting)

`Zero-shot Prompting (제로샷 프롬프팅)`은 모델에게 예시나 데모 없이 직접 작업을 수행하도록 지시하는 기법이다.

**특징:**
- 추가 예시 없이 프롬프트만으로 작업 수행
- 최신 LLM(GPT-3.5, GPT-4, Claude 등)은 강력한 제로샷 능력을 보유
- Instruction tuning과 RLHF(Reinforcement Learning from Human Feedback)로 개선됨

**예시:**
```
다음 텍스트의 감정을 분석해주세요: "오늘 날씨가 정말 좋네요!"
```

**장점:**
- 간단하고 빠름
- 추가 예시 준비 불필요
- 다양한 작업에 즉시 적용 가능

**단점:**
- 복잡한 작업에서는 성능이 제한적
- 모델이 이해하지 못하는 작업은 실패할 수 있음

### 퓨샷 프롬프팅 (Few-shot Prompting)

`Few-shot Prompting (퓨샷 프롬프팅)`은 프롬프트에 몇 가지 예시를 포함하여 모델이 패턴을 학습하도록 하는 기법이다.

**특징:**
- 프롬프트에 입력-출력 예시를 포함
- In-context learning을 통해 패턴 학습
- 모델이 충분히 크면(Kaplan et al., 2020)[^kaplan2020scaling] 퓨샷 능력이 나타남

**예시:**
```
다음은 단어를 문장에 사용하는 예시입니다:

단어: "fantastic"
문장: "The weather today is fantastic!"

단어: "delicious"
문장: "This pizza tastes delicious!"

단어: "amazing"
문장: 
```

**장점:**
- 제로샷보다 더 나은 성능
- 특정 형식이나 스타일을 학습시킬 수 있음
- Fine-tuning 없이도 특정 작업에 특화 가능

**단점:**
- 토큰 사용량 증가로 비용 상승
- 예시 선택이 성능에 큰 영향
- 모든 작업에서 효과적이지 않음 (특히 전문 지식이 필요한 경우)

### CoT 프롬프팅 (Chain-of-Thought Prompting)

`Chain-of-Thought Prompting (CoT 프롬프팅, 사고 연쇄 프롬프팅)`은 모델이 단계별로 추론 과정을 거쳐 답변하도록 유도하는 기법이다.

**특징:**
- 복잡한 문제를 단계별로 나누어 해결
- 추론 과정을 명시적으로 생성
- 산술, 상식 추론, 기호 추론 작업에서 효과적

**Zero-shot CoT:**
- "Let's think step by step" 같은 구문 추가
- 예시 없이도 추론 과정 유도

**Few-shot CoT:**
- 추론 과정이 포함된 예시 제공
- 더 복잡한 추론 패턴 학습

**예시 (Zero-shot CoT):**
```
다음 문제를 단계별로 풀어보세요.

문제: 한 상자에 사과가 5개 있습니다. 3개를 더 넣으면 총 몇 개가 될까요?

단계별로 생각해보겠습니다:
```

**장점:**
- 복잡한 문제 해결 능력 향상
- 추론 과정을 확인할 수 있어 신뢰성 증가
- 오류를 추적하고 수정하기 쉬움

**단점:**
- 더 긴 응답으로 인한 토큰 비용 증가
- 항상 정확한 추론을 보장하지는 않음

### 검색 증강 생성 (RAG)

`Retrieval-Augmented Generation (RAG, 검색 증강 생성)`은 외부 지식 베이스에서 관련 정보를 검색하여 LLM의 컨텍스트에 추가하는 기법이다.

**특징:**
- 외부 데이터 소스에서 정보 검색
- 검색된 정보를 프롬프트에 포함
- 할루시네이션 감소와 최신 정보 활용 가능

**작동 방식:**

1. **검색 (Retrieval)**
   - 사용자 질문을 벡터로 변환 (임베딩)
   - 지식 베이스에서 유사한 문서 검색
   - 관련성 높은 문서 선택

2. **증강 (Augmentation)**
   - 검색된 문서를 프롬프트에 포함
   - 원본 질문과 함께 LLM에 전달

3. **생성 (Generation)**
   - 증강된 컨텍스트를 바탕으로 답변 생성
   - 검색된 정보를 참조하여 답변

**예시 구조:**
```
다음 문서를 참고하여 질문에 답변해주세요:

[검색된 문서 1]
[검색된 문서 2]
[검색된 문서 3]

질문: [사용자 질문]
```

**장점:**
- 최신 정보 활용 가능
- 할루시네이션 감소
- 도메인 특화 지식 통합
- 답변의 근거 제공 가능

**단점:**
- 검색 품질에 의존
- 검색된 정보가 부정확할 수 있음
- 구현 복잡도 증가
- 검색 및 임베딩 비용 발생

**RAG의 핵심 구성 요소:**
- **벡터 데이터베이스**: 문서 임베딩 저장
- **임베딩 모델**: 텍스트를 벡터로 변환
- **검색 알고리즘**: 유사도 기반 검색
- **프롬프트 구성**: 검색 결과를 프롬프트에 통합

---

## 참고 문헌

[^kaplan2020scaling]: Kaplan, J., McCandlish, S., Henighan, T., Brown, T. B., Chess, B., Child, R., ... & Amodei, D. (2020). Scaling laws for neural language models. arXiv preprint arXiv:2001.08361. [arXiv 링크](https://arxiv.org/abs/2001.08361)

